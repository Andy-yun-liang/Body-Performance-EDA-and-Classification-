---
title: "performance"
output: html_document
author: Andy Liang
---

```{r}
library(caret)
library(tidymodels)
library(ggplot2) #visualization package
library(discrim)
library(MASS)
library(tidyverse)
library(nnet) # for multinomial logistic regression
library(ggcorrplot) #for colorful correlation plot
library(randomForest) #for random forest
library(xgboost)
library(kernlab)
library(parsnip)
library(treesnip)
library(plyr)
library(pROC)
library(GGally)
library(ranger)
library(stacks)
library(kknn)
library(LiblineaR)
```




```{r}
df = read.csv("bodyPerformance.csv")
```



```{r}
df$gender = as.integer(as.factor(df$gender))-1
df$class = as.factor(df$class)
df$bmi = (df$weight/(df$height)^2)*10000
str(df)
```

```{r}
summary(df)
#note: we have a balance set of class labels in this dataset and the dataset is complete (no missing values)
colnames(df) = c("age","gender","height","weight","bodyfat","diastolic","systolic","gripforce","seated_forward_bend","sit_ups","broad_jump","class","bmi")
```

#removing duplicated observations
```{r}
df = df[!duplicated(df),]
```


#df dataframe is data visualization rdy ^
```{r}
library(GGally)
sample_df <- df %>% group_by(class) %>% sample_n(500)

ggpairs(data = sample_df,
       mapping = aes(color = class),
        columns = c("gripforce", "seated_forward_bend", "sit_ups", "broad_jump"),
        upper = list(continuous = wrap("cor", size = 4.75,alignPercent = 0.5))
       )

```








#Tidymodels Framework


#split train and test set
```{r}
library(tidymodels)
library(doParallel)
all_cores <- parallel::detectCores(logical = FALSE)
registerDoParallel(cores = all_cores)

set.seed(123)

split = initial_split(df,prop = 0.7)

train_data = training(split)

test_data = testing(split)
```



#recipe
```{r}
#data preprocessing: 
#1.remove low variance features
#2.remove highly correlated features (threshold is 0.9)
#3.scale the features
dat_recipe = recipe(class~.,data=train_data) %>% step_nzv(all_predictors()) %>% step_corr(all_numeric(),-all_outcomes()) %>% step_normalize(all_predictors()) %>% prep()

```


#create cross validation folds, we are going to use 5fold
```{r}
set.seed(123)
my_folds = bake(dat_recipe,new_data = train_data) %>% vfold_cv(v=5)

```



#linear discriminant model
```{r}
lda_mod = discrim_linear(mode = "classification",
  engine = "MASS")
```


#auc plot and confusion matrix
```{r}
lda_mod = workflow() %>% add_recipe(dat_recipe) %>% add_model(lda_mod) %>% last_fit(split)

lda_mod %>% show_best(metric="accuracy")

lda_mod %>% show_best(metric="roc_auc")

lda_mod %>% collect_predictions() %>% roc_curve(class,.pred_A:.pred_D) %>% autoplot()


(lda_preds =lda_mod %>% collect_predictions() %>% conf_mat(truth = class, estimate = .pred_class))

```







#random forest model
```{r}

rf_mod = rand_forest(
  mtry = tune(),
  min_n = tune(),
  trees= 500) %>% set_mode("classification") %>% set_engine("ranger")


```


#rf work flow
```{r}
rf_wf = workflow() %>% add_recipe(dat_recipe)%>% add_model(rf_mod)
```


#rf results
```{r}

set.seed(123)
rf_results = rf_wf %>% tune_grid(
                                 resamples = my_folds,
                                 metrics = metric_set(roc_auc),
                                 grid=20
                                 )


```


#visualization for tuning
```{r}
rf_results %>% collect_metrics() %>%
  filter(.metric == "roc_auc") %>%
  pivot_longer(min_n:mtry,values_to = "val",names_to = "params") %>%
  ggplot(aes(val,mean,color = params)) + geom_point() + facet_wrap(~params,scales="free_x")

#looking at this plot we can see that we want lower values of min_n and values between ~4 and ~8 for mtry


```

#narrowing the best fit
```{r}
rf_grid = expand.grid(mtry = seq(4,8),min_n = seq(1,10))

set.seed(123)
rf_tune_res = rf_wf %>% tune_grid(resamples = my_folds,
                                  control = control_grid(save_pred=TRUE,save_workflow = TRUE),
                                  grid = rf_grid
                                  )


```

#plotting the best combination of parameters 
```{r}
#plot a visualization
rf_tune_res %>% collect_metrics() %>% filter(.metric == "roc_auc") %>%
  mutate(min_n = factor(min_n)) %>% ggplot(aes(mtry,mean,color=min_n)) + geom_line() +geom_point()


#looks like the best combination is mtry =7, and min_n =8

best_rf_params = rf_tune_res %>% select_best(metric= "roc_auc")


```


#accuracy roc_auc / auc plot and confusion matrix
```{r}

final_rf_mod = rf_wf %>% finalize_workflow(best_rf_params)

#using the model on the test set
final_rf_fit = final_rf_mod %>% last_fit(split)

#roc_auc 
final_rf_fit %>% show_best(metric="roc_auc")

#accuracy
final_rf_fit %>% show_best(metric="accuracy")


#auc plot of the test set
final_rf_fit %>% collect_predictions() %>% roc_curve(class,.pred_A:.pred_D) %>% mutate(model = "Random Forest") %>% autoplot()

#get confusion matrix
(test_preds = final_rf_fit %>% collect_predictions() %>% conf_mat(truth = class, estimate = .pred_class))


```


#Logistic Multinomial
```{r}
lr_mod = multinom_reg(
  mode = "classification",
  engine = "nnet",
  penalty = NULL,
  mixture = NULL
  )
```


#workflow
```{r}
lr_wf = workflow() %>% add_recipe(dat_recipe)%>% add_model(lr_mod) 
```

#accuracy roc_auc / auc plot and confusion matrix
```{r}
lr_fit = lr_wf %>% last_fit(split)


#roc_auc 
lr_fit %>% show_best(metric="roc_auc")

#accuracy
lr_fit %>% show_best(metric="accuracy")


#auc plot of the test set
lr_fit %>% collect_predictions() %>% roc_curve(class,.pred_A:.pred_D) %>% mutate(model = "multinomial") %>% autoplot()

#get confusion matrix
(lr_test_preds = lr_fit %>% collect_predictions() %>% conf_mat(truth = class, estimate = .pred_class))

```




#KNN
```{r}
knn_mod=nearest_neighbor(
  mode = "classification",
  engine = "kknn",
  neighbors = tune(),
  weight_func = tune(),
  dist_power = NULL
)
```

#knn workflow
```{r}
knn_wf = workflow() %>% add_recipe(dat_recipe) %>% add_model(knn_mod)
```

#knn tune
```{r}
set.seed(123)
knn_results = knn_wf %>% tune_grid(
                                 resamples = my_folds,
                                 metrics = metric_set(roc_auc),
                                 grid=40
                                 )


```

#Visualization of n neighbors
```{r}
#plot a visualization
knn_results %>% collect_metrics() %>% filter(.metric == "roc_auc") %>% mutate("weight_func" = factor(weight_func)) %>%
ggplot(aes(neighbors,mean, color = weight_func)) + geom_line() +geom_point()

#looks like more neighbors with weight functions: epanechnikov, inv, rank, and rectangular produces higher accuracy

```

#knn tune
```{r}
knn_grid = expand.grid(weight_func = c("epanechnikov","inv","rank","rectangular"), neighbors = c(7,9,11,13,15,17,20,23,25,30))

set.seed(123)
knn_tune_res = knn_wf %>% tune_grid(resamples = my_folds,
                                  control = control_grid(save_pred=TRUE,save_workflow = TRUE),
                                  grid = knn_grid
                                  )


```


```{r}
#plot a visualization
knn_tune_res %>% collect_metrics() %>% filter(.metric == "roc_auc") %>% mutate("weight_func" = factor(weight_func)) %>%
ggplot(aes(neighbors,mean, color = weight_func)) + geom_line() +geom_point()


(best_knn_params = knn_tune_res %>% select_best(metric= "roc_auc"))

```


```{r}
final_knn_mod = knn_wf %>% finalize_workflow(best_knn_params)

#using the model on the test set
final_knn_fit = final_knn_mod %>% last_fit(split)

#roc_auc 
final_knn_fit %>% show_best(metric="roc_auc")

#accuracy
final_knn_fit %>% show_best(metric="accuracy")


#auc plot of the test set
final_knn_fit %>% collect_predictions() %>% roc_curve(class,.pred_A:.pred_D) %>% autoplot()

#get confusion matrix
(knn_test_preds = final_knn_fit %>% collect_predictions() %>% conf_mat(truth = class, estimate = .pred_class))


```




#XGBoost
```{r}
XGBoost_mod = boost_tree( mode = "classification",
                      engine = "xgboost",
                      mtry = tune(),
                      trees = 800,
                      tree_depth = tune(),
                      min_n = tune(),
                      loss_reduction = tune(),
                      sample_size = tune(),
                      learn_rate = tune()
                      )


XGB_grid = grid_max_entropy(finalize(mtry(),train_data),
                            learn_rate(),
                            sample_size = sample_prop(),
                            min_n(),
                            tree_depth(),
                            loss_reduction(),
                            size=25)

```



#xgb wf
```{r}
XGB_wf = workflow() %>% add_recipe(dat_recipe) %>% add_model(XGBoost_mod)
```

```{r}
set.seed(123)
XGB_tune_res = XGB_wf %>% tune_grid(resamples = my_folds,
                                  control = control_grid(save_pred=TRUE,save_workflow = TRUE),
                                  grid = XGB_grid
                                  )

```


```{r}

best_XGB_params = XGB_tune_res %>% select_best(metric= "roc_auc")


final_XGB_mod = XGB_wf %>% finalize_workflow(best_XGB_params)


#using the model on the test set
final_XGB_fit  = final_XGB_mod %>% last_fit(split)

#roc_auc and accuracy
final_XGB_fit %>% collect_metrics()

#auc plot of the test set
final_XGB_fit %>% collect_predictions(parameters = best_XGB_params) %>% roc_curve(class,.pred_A:.pred_D) %>% mutate(model = "XGB") %>% autoplot()

#get confusion matrix
(XGB_test_preds = final_XGB_fit %>% collect_predictions() %>% conf_mat(truth = class, estimate = .pred_class))
```




#LightGBM
```{r}
set_dependency("boost_tree", eng = "lightgbm", "lightgbm")
set_dependency("boost_tree", eng = "lightgbm", "treesnip")


LightGBM_mod = boost_tree(mode = "classification",
                          engine = "lightgbm",
                          mtry = tune(),
                          trees = 1000, 
                          min_n = tune(),
                          tree_depth = tune(),
                          loss_reduction = tune(),
                          learn_rate = tune(), 
                          sample_size = tune())


LightGBM_wf = workflow() %>% add_recipe(dat_recipe) %>% add_model(LightGBM_mod)




set.seed(123)

LightGBM_tune_res = LightGBM_wf %>% tune_grid(resamples = my_folds,
                                  control = control_grid(save_pred=TRUE,save_workflow = TRUE),
                                  grid = 20
                                  )



```


```{r}

LightGBM_tune_res %>% collect_metrics() %>% filter(.metric == "roc_auc") %>%
  pivot_longer(mtry:loss_reduction,values_to = "val",names_to = "params") %>%
  ggplot(aes(val,mean,color = params)) + geom_point() + facet_wrap(~params,scales="free_x")


best_LightGBM_params = LightGBM_tune_res %>% show_best(metric= "roc_auc")

```

#finalizing LightGBM model
```{r}
final_LightGBM_mod = LightGBM_wf %>% finalize_workflow(best_LightGBM_params[1,])


#using the model on the test set
final_LightGBM_fit  = final_LightGBM_mod %>% last_fit(split)

#roc_auc and accuracy
final_LightGBM_fit %>% collect_metrics()

#auc plot of the test set
final_LightGBM_fit %>% collect_predictions(parameters = best_LightGBM_params) %>% roc_curve(class,.pred_A:.pred_D) %>% mutate(model = "LightGBM") %>% autoplot()

#get confusion matrix
(LightGBM_test_preds = final_LightGBM_fit %>% collect_predictions() %>% conf_mat(truth = class, estimate = .pred_class))
```


#SVM rbf model
```{r}
svmRBF_mod =svm_rbf(mode = "classification",
                    engine="kernlab",
                    cost = tune(),
                    rbf_sigma = tune())



svmRBF_wf = workflow() %>% add_recipe(dat_recipe) %>% add_model(svmRBF_mod)




set.seed(123)
svmRBF_tune_res = svmRBF_wf %>% tune_grid(resamples = my_folds,
                                  control = control_grid(save_pred=TRUE),
                                  grid = 20
                                  )


```


```{r}
svmRBF_tune_res %>% collect_metrics() %>% filter(.metric == "roc_auc") %>%
  pivot_longer(cost:rbf_sigma, values_to = "val",names_to = "params") %>%
  ggplot(aes(val,mean,color = params)) + geom_point() + facet_wrap(~params,scales="free_x")

#we can see that lower cost values are preferred. (can't say for rbf_sigma so we can try a range of numbers for the next tune)
```


```{r}
svmRBF_grid = expand.grid(cost = c(0.5,1,2,3,4),rbf_sigma = c(0,0.1,0.2,0.4,0.5,0.7))

svmRBF_tune_res = svmRBF_wf %>% tune_grid(resamples = my_folds,
                                  control = control_grid(save_pred=TRUE,save_workflow = TRUE),
                                  grid = svmRBF_grid 
                                  )

```

#finalizing SVM_RBF model
```{r}
best_svmRBF_params = svmRBF_tune_res %>% show_best(metric= "roc_auc")

final_svmRBF_mod = svmRBF_wf %>% finalize_workflow(best_svmRBF_params[1,])


#using the model on the test set
final_svmRBF_fit  = final_svmRBF_mod %>% last_fit(split)

#roc_auc and accuracy
final_svmRBF_fit %>% collect_metrics()

#auc plot of the test set
final_svmRBF_fit %>% collect_predictions(parameters = best_svmRBF_params) %>% roc_curve(class,.pred_A:.pred_D) %>% autoplot()

#get confusion matrix
(svmRBFtest_preds = final_svmRBF_fit %>% collect_predictions() %>% conf_mat(truth = class, estimate = .pred_class))
```


#multi layer perceptron
```{r}
mlp_mod = mlp(mode="classification",
              engine = "nnet",
              hidden_units = tune(),
              penalty = tune(),
              epochs = tune())


mlp_wf = workflow() %>% add_recipe(dat_recipe) %>% add_model(mlp_mod)




set.seed(123)
mlp_tune_res = mlp_wf %>% 
  tune_grid(resamples = my_folds,
            control=control_grid(save_pred=TRUE,save_workflow = TRUE),
            grid = 20
                                  )
best_mlp_params = mlp_tune_res %>% show_best(metric= "roc_auc")


```

#finalizing mlp model
```{r}
final_mlp_mod = mlp_wf %>% finalize_workflow(best_mlp_params[1,])


#using the model on the test set
final_mlp_fit  = final_mlp_mod %>% last_fit(split)

#roc_auc and accuracy
final_mlp_fit %>% collect_metrics()

#auc plot of the test set
final_mlp_fit %>% collect_predictions(parameters = best_mlp_params) %>% roc_curve(class,.pred_A:.pred_D) %>% autoplot()

#get confusion matrix
(mlp_preds = final_mlp_fit %>% collect_predictions() %>% conf_mat(truth = class, estimate = .pred_class))
```



#aggregating the data to make a roc_auc plot
```{r}
#lda
lda_collection = lda_mod %>% 
collect_predictions() %>% mutate(.config = "lda")

#logistic multinomial
lr_collection = lr_fit %>% collect_predictions() %>% mutate(.config = "multi")

#svm_rbf
svm_collection = final_svmRBF_fit %>% collect_predictions() %>% mutate(.config = "svm")

#knn
knn_collection = final_knn_fit %>% 
collect_predictions(parameters = best_knn_params)%>% mutate(.config = "knn")

#rf
rf_collection = final_rf_fit %>% 
collect_predictions(parameters = best_rf_params)%>% mutate(.config = "rf")

#mlp 
mlp_collection = final_mlp_fit %>% 
collect_predictions(parameters = best_mlp_params)%>% mutate(.config = "mlp")

#xgb
xgb_collection = final_XGB_fit %>% 
collect_predictions(parameters = best_XGB_params)%>% mutate(.config = "xgb")

#lgbm
lgbm_collection = as.data.frame(final_LightGBM_fit %>% 
collect_predictions(parameters = best_LightGBM_params[1,])%>% mutate(.config = "lgbm"))



all_sets = rbind(lgbm_collection,rf_collection,xgb_collection,svm_collection,lr_collection,mlp_collection,lda_collection,knn_collection)

```






```{r}
all_sets %>% mutate(model = .config) %>%
  group_by(model) %>% #group by model name
  roc_curve(class,.pred_A:.pred_D) %>% 
  ggplot(
    aes(
      x = 1 - specificity, 
      y = sensitivity, 
      color = model
    )
  ) + 
  geom_line(size = 0.9) +
  geom_abline(slope = 1, intercept = 0, size = 0.4)


```



#auc scores
```{r}

all_sets %>%
  group_by(.config) %>% 
  roc_auc(class,.pred_A:.pred_D) %>% arrange(desc(.estimate))

```

#accuracy score (proportion of data that are predicted correctly)
```{r}
all_sets %>%
  group_by(.config) %>% 
  accuracy(class,.pred_class) %>% arrange(desc(.estimate))
```


